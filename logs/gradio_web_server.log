2024-05-08 19:14:14 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:14:14 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:14:14 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:14:14 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:14:15 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:14:16 | INFO | stdout | 
2024-05-08 19:14:16 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:14:24 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:14:24 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/queueing.py", line 527, in process_events
2024-05-08 19:14:24 | ERROR | stderr |     response = await route_utils.call_process_api(
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:14:24 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1847, in process_api
2024-05-08 19:14:24 | ERROR | stderr |     result = await self.call_function(
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1445, in call_function
2024-05-08 19:14:24 | ERROR | stderr |     prediction = await utils.async_iteration(iterator)
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 629, in async_iteration
2024-05-08 19:14:24 | ERROR | stderr |     return await iterator.__anext__()
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 622, in __anext__
2024-05-08 19:14:24 | ERROR | stderr |     return await anyio.to_thread.run_sync(
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-05-08 19:14:24 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2144, in run_sync_in_worker_thread
2024-05-08 19:14:24 | ERROR | stderr |     return await future
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-05-08 19:14:24 | ERROR | stderr |     result = context.run(func, *args)
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 605, in run_sync_iterator_async
2024-05-08 19:14:24 | ERROR | stderr |     return next(iterator)
2024-05-08 19:14:24 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 788, in gen_wrapper
2024-05-08 19:14:24 | ERROR | stderr |     response = next(iterator)
2024-05-08 19:14:24 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 170, in http_bot
2024-05-08 19:14:24 | ERROR | stderr |     if state.skip_next:
2024-05-08 19:14:24 | ERROR | stderr | AttributeError: 'NoneType' object has no attribute 'skip_next'
2024-05-08 19:14:25 | INFO | stdout | {'text': '请针对于这幅画写一首中文古诗。', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/0266b3f7b9311a93f0f38bc8cf0698b019c829b1/user_example_09.jpg']}
2024-05-08 19:14:29 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 15
2024-05-08 19:16:18 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:16:18 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:16:18 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:16:18 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:16:19 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:16:20 | INFO | stdout | 
2024-05-08 19:16:20 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:16:22 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:16:22 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/queueing.py", line 527, in process_events
2024-05-08 19:16:22 | ERROR | stderr |     response = await route_utils.call_process_api(
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:16:22 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1847, in process_api
2024-05-08 19:16:22 | ERROR | stderr |     result = await self.call_function(
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1445, in call_function
2024-05-08 19:16:22 | ERROR | stderr |     prediction = await utils.async_iteration(iterator)
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 629, in async_iteration
2024-05-08 19:16:22 | ERROR | stderr |     return await iterator.__anext__()
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 622, in __anext__
2024-05-08 19:16:22 | ERROR | stderr |     return await anyio.to_thread.run_sync(
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-05-08 19:16:22 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2144, in run_sync_in_worker_thread
2024-05-08 19:16:22 | ERROR | stderr |     return await future
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-05-08 19:16:22 | ERROR | stderr |     result = context.run(func, *args)
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 605, in run_sync_iterator_async
2024-05-08 19:16:22 | ERROR | stderr |     return next(iterator)
2024-05-08 19:16:22 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 788, in gen_wrapper
2024-05-08 19:16:22 | ERROR | stderr |     response = next(iterator)
2024-05-08 19:16:22 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 170, in http_bot
2024-05-08 19:16:22 | ERROR | stderr |     if state.skip_next:
2024-05-08 19:16:22 | ERROR | stderr | AttributeError: 'NoneType' object has no attribute 'skip_next'
2024-05-08 19:16:30 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:16:34 | INFO | stdout | {'text': '请针对于这幅画写一首中文古诗。', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/0266b3f7b9311a93f0f38bc8cf0698b019c829b1/user_example_09.jpg']}
2024-05-08 19:16:38 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 15
2024-05-08 19:16:51 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:16:51 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/routes.py", line 733, in predict
2024-05-08 19:16:51 | ERROR | stderr |     output = await route_utils.call_process_api(
2024-05-08 19:16:51 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:16:51 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:16:51 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1856, in process_api
2024-05-08 19:16:51 | ERROR | stderr |     data = await self.postprocess_data(fn_index, result["prediction"], state)
2024-05-08 19:16:51 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1684, in postprocess_data
2024-05-08 19:16:51 | ERROR | stderr |     prediction_value = block.postprocess(prediction_value)
2024-05-08 19:16:51 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/multimodal_textbox.py", line 160, in postprocess
2024-05-08 19:16:51 | ERROR | stderr |     raise ValueError(
2024-05-08 19:16:51 | ERROR | stderr | ValueError: MultimodalTextbox expects a dictionary with optional keys 'text' and 'files'. Received str
2024-05-08 19:19:24 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:19:27 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:19:30 | INFO | stdout | {'text': 'この猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/b7b8f04e74cda37d9a574c1a2098d7e4ee97b212/user_example_05.jpg']}
2024-05-08 19:19:33 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:19:33 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 37
2024-05-08 19:19:39 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:19:39 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:19:39 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/routes.py", line 733, in predict
2024-05-08 19:19:39 | ERROR | stderr |     output = await route_utils.call_process_api(
2024-05-08 19:19:39 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:19:39 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:19:39 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1856, in process_api
2024-05-08 19:19:39 | ERROR | stderr |     data = await self.postprocess_data(fn_index, result["prediction"], state)
2024-05-08 19:19:39 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1684, in postprocess_data
2024-05-08 19:19:39 | ERROR | stderr |     prediction_value = block.postprocess(prediction_value)
2024-05-08 19:19:39 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/multimodal_textbox.py", line 160, in postprocess
2024-05-08 19:19:39 | ERROR | stderr |     raise ValueError(
2024-05-08 19:19:39 | ERROR | stderr | ValueError: MultimodalTextbox expects a dictionary with optional keys 'text' and 'files'. Received str
2024-05-08 19:19:39 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\n请针对于这幅画写一首中文古诗。<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['14dc2eeafa58f977589b57749e8b0eeb']"}
2024-05-08 19:19:57 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:20:00 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:20:00 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:20:00 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nこの猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['6a216b113245e21e8b9f3b2f14599730']"}
2024-05-08 19:20:09 | INFO | gradio_web_server | この猫の目の大きさが他の猫と比べて特に大きく見える理由は、写真の角度と焦点の設定によるものです。写真は猫の顔から正面から撮影されており、猫の目がカメラに近づいているため、焦点が目に集中しています。これにより、猫の目がより大きく、より鮮明に見える効果が生じます。また、猫の顔が正面から撮影されているため、目が正面に直角に配置されているように見えることも、目が大きく見える要因の一つです。
2024-05-08 19:23:09 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:23:09 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:23:09 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:23:09 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:23:09 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:23:09 | INFO | stdout | 
2024-05-08 19:23:09 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:23:12 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:23:14 | INFO | stdout | {'text': 'この猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/b7b8f04e74cda37d9a574c1a2098d7e4ee97b212/user_example_05.jpg']}
2024-05-08 19:23:20 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 37
2024-05-08 19:23:28 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:23:38 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:23:38 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:23:38 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nこの猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['6a216b113245e21e8b9f3b2f14599730']"}
2024-05-08 19:23:45 | INFO | gradio_web_server | この猫の目の大きさが他の猫と比べて特に大きく見える理由は、写真の角度と焦点の位置によるものです。写真は猫の正面から撮影されており、猫の目がカメラに直面しているため、目がより目立つように写っています。また、猫の顔が写真の中心に配置されているため、視覚的に目がより大きさを感じさせられます。実際の猫の目は、この写真で見たようには大きくないことが一般的です。
2024-05-08 19:24:06 | INFO | gradio_web_server | clear_history. ip: 124.246.66.198
2024-05-08 19:24:06 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:24:06 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/routes.py", line 733, in predict
2024-05-08 19:24:06 | ERROR | stderr |     output = await route_utils.call_process_api(
2024-05-08 19:24:06 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:24:06 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:24:06 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1856, in process_api
2024-05-08 19:24:06 | ERROR | stderr |     data = await self.postprocess_data(fn_index, result["prediction"], state)
2024-05-08 19:24:06 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1684, in postprocess_data
2024-05-08 19:24:06 | ERROR | stderr |     prediction_value = block.postprocess(prediction_value)
2024-05-08 19:24:06 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/multimodal_textbox.py", line 160, in postprocess
2024-05-08 19:24:06 | ERROR | stderr |     raise ValueError(
2024-05-08 19:24:06 | ERROR | stderr | ValueError: MultimodalTextbox expects a dictionary with optional keys 'text' and 'files'. Received str
2024-05-08 19:25:17 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:25:17 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:25:17 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:25:17 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:25:18 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:25:18 | INFO | stdout | 
2024-05-08 19:25:18 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:25:23 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:25:30 | INFO | stdout | {'text': 'この猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/b7b8f04e74cda37d9a574c1a2098d7e4ee97b212/user_example_05.jpg']}
2024-05-08 19:25:30 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 37
2024-05-08 19:25:31 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:25:31 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:25:31 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:25:31 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nこの猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['6a216b113245e21e8b9f3b2f14599730']"}
2024-05-08 19:25:38 | INFO | gradio_web_server | この猫の目の大きさが他の猫と比べて特に大きく見える理由は、写真の角度と焦点の位置によるものです。写真は猫の正面から撮影されており、猫の目がカメラに近づいているため、目がより大きく見える効果が発生しています。また、猫の顔が写真の中央に配置されているため、視覚的に目がより目立つ効果も発生しています。
2024-05-08 19:25:48 | INFO | stdout | {'text': 'Please translate it to English', 'files': []}
2024-05-08 19:25:48 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 30
2024-05-08 19:25:49 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:25:49 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:25:49 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:25:49 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nPlease translate it to English<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': 'List of 0 images: []'}
2024-05-08 19:25:49 | INFO | gradio_web_server | Please translate it to English.
2024-05-08 19:26:11 | INFO | stdout | {'text': '请针对于这幅画写一首中文古诗。', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/0266b3f7b9311a93f0f38bc8cf0698b019c829b1/user_example_09.jpg']}
2024-05-08 19:26:11 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 15
2024-05-08 19:26:12 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:26:12 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:26:12 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:26:12 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\n请针对于这幅画写一首中文古诗。<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['14dc2eeafa58f977589b57749e8b0eeb']"}
2024-05-08 19:26:18 | INFO | gradio_web_server | 星河灿烂，月光洒落，
山丘静谧，村庄安详。
梵高笔下，色彩斑斓，
描绘星空，尽展辉煌。

夜幕降临，月升天际，
繁星点点，如梦似幻。
梵高之笔，挥洒自如，
画出宇宙，尽展壮阔。

村庄静谧，月光洒落，
梵高之心，尽展辉煌。
星空灿烂，月光洒落，
尽展梵高，艺术之光。
2024-05-08 19:26:21 | INFO | gradio_web_server | regenerate. ip: 124.246.66.198
2024-05-08 19:26:22 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:26:22 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:26:22 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:26:22 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\n请针对于这幅画写一首中文古诗。<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['14dc2eeafa58f977589b57749e8b0eeb']"}
2024-05-08 19:26:28 | INFO | gradio_web_server | 星河灿烂，月光洒落，
山丘静谧，村庄安详。
梵高笔下，色彩斑斓，
描绘星空，尽展辉煌。

夜空深邃，繁星点点，
月亮高挂，如梦似幻。
梵高之笔，挥洒自如，
画出宇宙，尽展神韵。

村庄静谧，月光洒落，
梵高之心，尽展画中。
星空灿烂，尽展辉煌，
梵高之笔，尽展神韵。
2024-05-08 19:26:31 | INFO | gradio_web_server | clear_history. ip: 124.246.66.198
2024-05-08 19:26:35 | INFO | stdout | {'text': 'Write the content of this table in a Notion format?', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/7dcdac5ff3df641ae7eb47d8b7aaeab740e02de9/user_example_06.jpg']}
2024-05-08 19:26:35 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 51
2024-05-08 19:26:35 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:26:35 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:26:35 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:26:35 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWrite the content of this table in a Notion format?<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['f232ae48c28a3bb13d630adc2b79b1f9']"}
2024-05-08 19:26:48 | INFO | gradio_web_server | Certainly! Here's the content of the table in a Notion format:

---

| Signal | Num | Type | Description |
| --- | --- | --- | --- |
| SIGKILL | 9 | AEF | Terminate the execution of the process |
| SIGTERM | 15 | A | Terminate the execution of the process |
| SIGSTOP | 17, 19, 23 | DEF | Stop the process |
| SIGCONT | 18 | DEF | Continue the execution of the process |
| SIGCHLD | 17 | B | A child process has finished |
| SIGUSR1 | 10 | A | Signal from the user |
| SIGUSR2 | 10 | A | Signal from the user |

---

Please note that the "Num" column lists the signal numbers, "Type" indicates the type of signal, and "Description" provides a brief explanation of what each signal does.
2024-05-08 19:26:59 | INFO | gradio_web_server | clear_history. ip: 124.246.66.198
2024-05-08 19:27:03 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:27:03 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:27:03 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:27:03 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:27:03 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:27:03 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:27:05 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:27:17 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:27:17 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:27:17 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:27:17 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:27:17 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:27:17 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:27:19 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:27:26 | INFO | gradio_web_server | clear_history. ip: 124.246.66.198
2024-05-08 19:27:28 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:27:28 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:27:28 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:27:28 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:27:28 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:27:28 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.0, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:27:49 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:27:49 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:27:49 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:27:49 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:27:49 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:27:49 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.2, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:27:51 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:28:13 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:28:13 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:28:14 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:28:14 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:28:14 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:28:14 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 1.0, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:28:15 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:28:19 | INFO | stdout | {'text': 'この猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/b7b8f04e74cda37d9a574c1a2098d7e4ee97b212/user_example_05.jpg']}
2024-05-08 19:28:19 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 37
2024-05-08 19:28:19 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:28:19 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:28:19 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:28:19 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nこの猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 1.0, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['6a216b113245e21e8b9f3b2f14599730']"}
2024-05-08 19:28:28 | INFO | gradio_web_server | この猫の目の大きさが他の猫と比べて特に大きく見える理由は、写真の角度と焦点の位置によるものです。写真は猫の正面から撮影されており、猫の目がカメラに直面しているため、目がより目立つように写っています。また、猫の顔が写真の中心に位置しており、他の部分が遠くに写っているため、猫の目がより目立つように写っています。この効果は、写真の構成と焦点の位置によって引き起こされる視覚的な効果です。
2024-05-08 19:28:31 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:28:31 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:28:31 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:28:31 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:28:31 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:28:32 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 1.0, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:28:34 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:28:51 | INFO | stdout | {'text': 'Explain this diagram.', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/7f718391e606e46b9d40e4948a1e8cb262335699/user_example_01.jpg']}
2024-05-08 19:28:51 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 21
2024-05-08 19:28:52 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:28:52 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:28:52 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:28:52 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nExplain this diagram.<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 1.0, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['91d6a4b55dd3ab9c0293c0dbd1ed2d4a']"}
2024-05-08 19:29:47 | INFO | gradio_web_server | The diagram you've provided appears to be a simplified representation of a computer system architecture, focusing on the hardware components and their connections. Here's a breakdown of the components and their functions as depicted in the diagram:

1. **CPU (Central Processing Unit)**: This is the brain of the computer, responsible for executing instructions and controlling the operation of the computer system.

2. **ROM (Read-Only Memory)**: This is a type of non-volatile memory that retains its data even when the power is turned off.

3. **RAM (Random Access Memory)**: This is a type of volatile memory that temporarily stores data that the CPU needs to access quickly.

4. **HDD (Hard Disk Drive)**: This is a non-volatile storage device that stores and retrieves digital information using one or more rigid rapidly rotating disks coated with magnetic material.

5. **Display**: This is the output device that allows the user to see the visual representation of the computer's output.

6. **Network (I/F)**: This stands for "Interface" and represents the hardware and software that allow the computer to communicate with other devices on a network.

7. **Keyboard**: This is an input device used to enter text or commands into the computer.

8. **Mouse**: This is an input device that allows the user to interact with the computer by pointing and clicking.

9. **Media (I/F)**: This likely refers to an interface for handling media, such as CDs or DVDs.

10. **CD-RW Drive**: This is a device that can read, write, and rewrite data on CD-RW discs.

11. **Recording Medium**: This could refer to any storage device used for recording data, such as a hard drive, CD, or DVD.

12. **304 (504)**: This could be a specific model or part number for a component, possibly a type of memory or storage device.

13. **305 (505)**: Similar to the above, this could be another model or part number for a component.

14. **308 (508)**: Again, this could be a model or part number for a component.

15. **310 (510)**: This could be a model or part number for a component, possibly a network interface card or a specific type of storage device.

16. **311 (511)**: This could be a model or part number for a component, possibly a keyboard or a mouse.

17. **312 (512)**: This could be a model or part number for a component, possibly a sound card or a specific type of storage device.

18. **313 (513)**: This could be a model or part number for a component, possibly a CD-RW drive or a specific type of storage device.

19. **314 (514)**: This could be a model or part number for a component, possibly a specific type of recording medium.

20. **309 (509)**: This could be a model or part number for a component, possibly a network interface card or a specific type of storage device.

21. **307 (507)**: This could be a model or part number for a component, possibly a specific type of storage device.

22. **306 (506)**: This could be a model or part number for a component, possibly a specific type of storage device.

The numbers in parentheses (e.g., 504, 505, etc.) might indicate a specific version or revision of the component, or they could be part numbers for the components used in the system.

The arrows indicate the flow of data or the connections between these components. For example, the CPU is connected to the RAM, ROM, and HDD, which suggests that the CPU can access data from these storage devices. The keyboard and mouse are connected to the CPU, indicating that they are input devices that send data to the CPU. The display is connected to the CPU, which means that the CPU sends data to the display for output.

The diagram is a bit abstract and lacks specific details about the connections and the nature of the components, but it gives a general idea of how the different parts of a computer system are connected and interact with each other.
2024-05-08 19:29:49 | INFO | gradio_web_server | upvote. ip: 124.246.66.198
2024-05-08 19:29:49 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:29:49 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/queueing.py", line 527, in process_events
2024-05-08 19:29:49 | ERROR | stderr |     response = await route_utils.call_process_api(
2024-05-08 19:29:49 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:29:49 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:29:49 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1856, in process_api
2024-05-08 19:29:49 | ERROR | stderr |     data = await self.postprocess_data(fn_index, result["prediction"], state)
2024-05-08 19:29:49 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1684, in postprocess_data
2024-05-08 19:29:49 | ERROR | stderr |     prediction_value = block.postprocess(prediction_value)
2024-05-08 19:29:49 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/multimodal_textbox.py", line 160, in postprocess
2024-05-08 19:29:49 | ERROR | stderr |     raise ValueError(
2024-05-08 19:29:49 | ERROR | stderr | ValueError: MultimodalTextbox expects a dictionary with optional keys 'text' and 'files'. Received str
2024-05-08 19:29:51 | INFO | gradio_web_server | clear_history. ip: 124.246.66.198
2024-05-08 19:34:33 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:34:33 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:34:33 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:34:33 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:34:34 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:34:34 | INFO | stdout | 
2024-05-08 19:34:34 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:34:40 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:34:42 | INFO | stdout | {'text': 'この猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/b7b8f04e74cda37d9a574c1a2098d7e4ee97b212/user_example_05.jpg']}
2024-05-08 19:34:42 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 37
2024-05-08 19:34:42 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:34:42 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:34:42 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:34:42 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nこの猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['6a216b113245e21e8b9f3b2f14599730']"}
2024-05-08 19:34:51 | INFO | gradio_web_server | この猫の目の大きさが他の猫と比べて特に大きく見える理由は、写真の角度と焦点の位置によるものです。写真は猫の顔から正面から撮影されており、猫の目がカメラに近づいているため、焦点が目に向かって集中しています。これにより、猫の目がより大きく、より鮮明に写っているように見えます。また、猫の顔が正面から撮影されているため、目が正面に直角に配置されているように見えることも、目が大きく見える要因の一つです。
2024-05-08 19:34:55 | INFO | gradio_web_server | upvote. ip: 124.246.66.198
2024-05-08 19:34:55 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:34:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/queueing.py", line 527, in process_events
2024-05-08 19:34:55 | ERROR | stderr |     response = await route_utils.call_process_api(
2024-05-08 19:34:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:34:55 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:34:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1856, in process_api
2024-05-08 19:34:55 | ERROR | stderr |     data = await self.postprocess_data(fn_index, result["prediction"], state)
2024-05-08 19:34:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1684, in postprocess_data
2024-05-08 19:34:55 | ERROR | stderr |     prediction_value = block.postprocess(prediction_value)
2024-05-08 19:34:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/multimodal_textbox.py", line 160, in postprocess
2024-05-08 19:34:55 | ERROR | stderr |     raise ValueError(
2024-05-08 19:34:55 | ERROR | stderr | ValueError: MultimodalTextbox expects a dictionary with optional keys 'text' and 'files'. Received str
2024-05-08 19:34:56 | INFO | gradio_web_server | downvote. ip: 124.246.66.198
2024-05-08 19:34:56 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:34:56 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/queueing.py", line 527, in process_events
2024-05-08 19:34:56 | ERROR | stderr |     response = await route_utils.call_process_api(
2024-05-08 19:34:56 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:34:56 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:34:56 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1856, in process_api
2024-05-08 19:34:56 | ERROR | stderr |     data = await self.postprocess_data(fn_index, result["prediction"], state)
2024-05-08 19:34:56 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1684, in postprocess_data
2024-05-08 19:34:56 | ERROR | stderr |     prediction_value = block.postprocess(prediction_value)
2024-05-08 19:34:56 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/multimodal_textbox.py", line 160, in postprocess
2024-05-08 19:34:56 | ERROR | stderr |     raise ValueError(
2024-05-08 19:34:56 | ERROR | stderr | ValueError: MultimodalTextbox expects a dictionary with optional keys 'text' and 'files'. Received str
2024-05-08 19:34:58 | INFO | gradio_web_server | flag. ip: 124.246.66.198
2024-05-08 19:34:58 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:34:58 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/queueing.py", line 527, in process_events
2024-05-08 19:34:58 | ERROR | stderr |     response = await route_utils.call_process_api(
2024-05-08 19:34:58 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 19:34:58 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 19:34:58 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1856, in process_api
2024-05-08 19:34:58 | ERROR | stderr |     data = await self.postprocess_data(fn_index, result["prediction"], state)
2024-05-08 19:34:58 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1684, in postprocess_data
2024-05-08 19:34:58 | ERROR | stderr |     prediction_value = block.postprocess(prediction_value)
2024-05-08 19:34:58 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/multimodal_textbox.py", line 160, in postprocess
2024-05-08 19:34:58 | ERROR | stderr |     raise ValueError(
2024-05-08 19:34:58 | ERROR | stderr | ValueError: MultimodalTextbox expects a dictionary with optional keys 'text' and 'files'. Received str
2024-05-08 19:37:16 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:37:16 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:37:16 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:37:16 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:37:16 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:37:17 | INFO | stdout | 
2024-05-08 19:37:17 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:37:19 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:37:21 | INFO | stdout | {'text': '请针对于这幅画写一首中文古诗。', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/0266b3f7b9311a93f0f38bc8cf0698b019c829b1/user_example_09.jpg']}
2024-05-08 19:37:21 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 15
2024-05-08 19:37:21 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:37:21 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:37:21 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:37:21 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\n请针对于这幅画写一首中文古诗。<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['14dc2eeafa58f977589b57749e8b0eeb']"}
2024-05-08 19:37:28 | INFO | gradio_web_server | 星河灿烂，月色如水，
山川静谧，村庄安详。
梵高笔下，色彩斑斓，
描绘星空，尽展辉煌。

夜幕降临，月升天际，
繁星点点，如梦似幻。
梵高之笔，挥洒自如，
画出宇宙，尽展神韵。

山丘起伏，村庄静谧，
梵高之心，尽展眼前。
星空璀璨，月色如水，
尽展梵高，艺术之神韵。
2024-05-08 19:37:30 | INFO | gradio_web_server | upvote. ip: 124.246.66.198
2024-05-08 19:41:41 | INFO | stdout | {'text': "What's more?", 'files': []}
2024-05-08 19:41:41 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 12
2024-05-08 19:41:41 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:41:41 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:41:41 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:41:41 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat's more?<|im_end|>\n<|im_start|>assistant\n", 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': 'List of 0 images: []'}
2024-05-08 19:41:43 | INFO | gradio_web_server | I'm sorry, but I'm not sure what you are asking. Could you please provide more context or clarify your question?
2024-05-08 19:41:45 | INFO | gradio_web_server | clear_history. ip: 124.246.66.198
2024-05-08 19:41:52 | INFO | gradio_web_server | upvote. ip: 124.246.66.198
2024-05-08 19:41:57 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/mnt/bn/vl-research/workspace/boli01/projects/demos/cache/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:41:57 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:41:57 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:41:57 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:41:57 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:41:57 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.2, 'top_p': 0.7, 'max_new_tokens': 512, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:41:59 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, s, d, s, and a.
2024-05-08 19:46:25 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:46:25 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:46:25 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:46:25 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:46:26 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:46:26 | INFO | stdout | 
2024-05-08 19:46:26 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:47:42 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:47:42 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:47:42 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:47:42 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:47:43 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:47:44 | INFO | stdout | 
2024-05-08 19:47:44 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:47:48 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:47:52 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/tmp/gradio/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:47:52 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:47:52 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:47:52 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:47:52 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:47:52 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:47:54 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:47:59 | INFO | gradio_web_server | upvote. ip: 124.246.66.198
2024-05-08 19:48:00 | INFO | stdout | [0, 1] The characters used in this captcha are: 6, t, q, b, c, d, s. True
2024-05-08 19:48:07 | ERROR | stderr | [31mERROR[0m:    Exception in ASGI application
2024-05-08 19:48:07 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/responses.py", line 327, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     stat_result = await anyio.to_thread.run_sync(os.stat, self.path)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-05-08 19:48:07 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2144, in run_sync_in_worker_thread
2024-05-08 19:48:07 | ERROR | stderr |     return await future
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-05-08 19:48:07 | ERROR | stderr |     result = context.run(func, *args)
2024-05-08 19:48:07 | ERROR | stderr | FileNotFoundError: [Errno 2] No such file or directory: '{PARENT_FOLDER}/assets/favicon.ico'
2024-05-08 19:48:07 | ERROR | stderr | 
2024-05-08 19:48:07 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-05-08 19:48:07 | ERROR | stderr | 
2024-05-08 19:48:07 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 411, in run_asgi
2024-05-08 19:48:07 | ERROR | stderr |     result = await app(  # type: ignore[func-returns-value]
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 69, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     return await self.app(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     await super().__call__(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     await self.middleware_stack(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     raise exc
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     await self.app(scope, receive, _send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 707, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     await self.app(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 65, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
2024-05-08 19:48:07 | ERROR | stderr |     raise exc
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
2024-05-08 19:48:07 | ERROR | stderr |     await app(scope, receive, sender)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/routing.py", line 756, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     await self.middleware_stack(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/routing.py", line 776, in app
2024-05-08 19:48:07 | ERROR | stderr |     await route.handle(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/routing.py", line 297, in handle
2024-05-08 19:48:07 | ERROR | stderr |     await self.app(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/routing.py", line 77, in app
2024-05-08 19:48:07 | ERROR | stderr |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
2024-05-08 19:48:07 | ERROR | stderr |     raise exc
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
2024-05-08 19:48:07 | ERROR | stderr |     await app(scope, receive, sender)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/routing.py", line 75, in app
2024-05-08 19:48:07 | ERROR | stderr |     await response(scope, receive, send)
2024-05-08 19:48:07 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/starlette/responses.py", line 330, in __call__
2024-05-08 19:48:07 | ERROR | stderr |     raise RuntimeError(f"File at path {self.path} does not exist.")
2024-05-08 19:48:07 | ERROR | stderr | RuntimeError: File at path {PARENT_FOLDER}/assets/favicon.ico does not exist.
2024-05-08 19:48:08 | INFO | gradio_web_server | load_demo. ip: 24.240.45.225. params: {}
2024-05-08 19:48:25 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-05-08 19:48:25 | ERROR | stderr | Error in sys.excepthook:
2024-05-08 19:48:25 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/linecache.py", line 46, in getlines
2024-05-08 19:48:25 | ERROR | stderr |     return updatecache(filename, module_globals)
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/linecache.py", line 136, in updatecache
2024-05-08 19:48:25 | ERROR | stderr |     with tokenize.open(fullname) as fp:
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/tokenize.py", line 394, in open
2024-05-08 19:48:25 | ERROR | stderr |     buffer = _builtin_open(filename, 'rb')
2024-05-08 19:48:25 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:48:25 | ERROR | stderr | 
2024-05-08 19:48:25 | ERROR | stderr | Original exception was:
2024-05-08 19:48:25 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2553, in block_thread
2024-05-08 19:48:25 | ERROR | stderr |     time.sleep(0.1)
2024-05-08 19:48:25 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:48:25 | ERROR | stderr | 
2024-05-08 19:48:25 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-05-08 19:48:25 | ERROR | stderr | 
2024-05-08 19:48:25 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/runpy.py", line 196, in _run_module_as_main
2024-05-08 19:48:25 | ERROR | stderr |     return _run_code(code, main_globals, None,
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/runpy.py", line 86, in _run_code
2024-05-08 19:48:25 | ERROR | stderr |     exec(code, run_globals)
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py", line 39, in <module>
2024-05-08 19:48:25 | ERROR | stderr |     cli.main()
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 430, in main
2024-05-08 19:48:25 | ERROR | stderr |     run()
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 284, in run_file
2024-05-08 19:48:25 | ERROR | stderr |     runpy.run_path(target, run_name="__main__")
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 321, in run_path
2024-05-08 19:48:25 | ERROR | stderr |     return _run_module_code(code, init_globals, run_name,
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 135, in _run_module_code
2024-05-08 19:48:25 | ERROR | stderr |     _run_code(code, mod_globals, init_globals,
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 124, in _run_code
2024-05-08 19:48:25 | ERROR | stderr |     exec(code, run_globals)
2024-05-08 19:48:25 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 606, in <module>
2024-05-08 19:48:25 | ERROR | stderr |     demo.queue(api_open=False).launch(
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2458, in launch
2024-05-08 19:48:25 | ERROR | stderr |     self.block_thread()
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2557, in block_thread
2024-05-08 19:48:25 | ERROR | stderr |     self.server.close()
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/http_server.py", line 68, in close
2024-05-08 19:48:25 | ERROR | stderr |     self.thread.join(timeout=5)
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1100, in join
2024-05-08 19:48:25 | ERROR | stderr |     self._wait_for_tstate_lock(timeout=max(timeout, 0))
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
2024-05-08 19:48:25 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-05-08 19:48:25 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:48:25 | ERROR | stderr | Exception ignored in: <module 'threading' from '/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py'>
2024-05-08 19:48:25 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:48:25 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1567, in _shutdown
2024-05-08 19:48:25 | ERROR | stderr |     lock.acquire()
2024-05-08 19:48:25 | ERROR | stderr | KeyboardInterrupt:
2024-05-08 19:48:26 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:48:26 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/pydevd.py", line 2299, in __wait_for_threads_to_finish
2024-05-08 19:48:26 | ERROR | stderr |     time.sleep(1 / 10.)
2024-05-08 19:48:26 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:48:41 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:48:41 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='reload', share=False, moderate=False, embed=False)
2024-05-08 19:48:41 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:48:41 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='reload', share=False, moderate=False, embed=False)
2024-05-08 19:48:41 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:48:41 | INFO | stdout | 
2024-05-08 19:48:41 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:48:49 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198
2024-05-08 19:48:49 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:48:52 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/tmp/gradio/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:48:52 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 65
2024-05-08 19:48:52 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:48:52 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:48:52 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:48:52 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:48:54 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:48:57 | INFO | stdout | {'text': 'fafa', 'files': []}
2024-05-08 19:48:57 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 4
2024-05-08 19:48:57 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:48:57 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:48:57 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:48:57 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nfafa<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': 'List of 0 images: []'}
2024-05-08 19:48:59 | INFO | gradio_web_server | I'm sorry, I'm not sure what you're trying to say. Can you please provide more context or information?
2024-05-08 19:49:05 | INFO | gradio_web_server | load_demo. ip: 24.240.45.225
2024-05-08 19:49:05 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:49:05 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198
2024-05-08 19:49:05 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:49:14 | INFO | stdout | {'text': 'What is the latex code for this image?', 'files': ['/tmp/gradio/a3cc6651cc472468fe9481a1d92fa5de88e2b76e/user_example_04.jpg']}
2024-05-08 19:49:14 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 38
2024-05-08 19:49:15 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 19:49:15 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:49:15 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:49:15 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat is the latex code for this image?<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['450ac58e36d9dd61d78c8b1247a5dffe']"}
2024-05-08 19:49:53 | INFO | stdout | {'text': "What's the difference between them?", 'files': ['/tmp/gradio/b7b8f04e74cda37d9a574c1a2098d7e4ee97b212/user_example_05.jpg', '/tmp/gradio/bd584df86fb00f971ddff082855b76179486b77a/brianbo_an_otter_is_standing_in_front_of_a_obelisk_in_fairy_tal_185a3c30-049e-47e3-95ac-c7c535a763f8.png']}
2024-05-08 19:49:53 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 35
2024-05-08 19:49:54 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:49:54 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:49:54 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:49:54 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat's the difference between them?<|im_end|>\n<|im_start|>assistant\n", 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 2 images: ['6a216b113245e21e8b9f3b2f14599730', '5ebe6fad6247a492c93f66cabd77e504']"}
2024-05-08 19:49:56 | INFO | gradio_web_server | The LaTeX code for the mathematical expressions in the image is as follows:

```latex
\begin{align*}
\Omega_{\ell} &= \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} \\
&= \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} \\
&= \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} \\
&= W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)}
\end{align*}
```

Please note that the LaTeX code provided is a transcription of the mathematical expressions shown in the image, and it may not be a complete or accurate representation of the intended mathematical content. The expressions involve summations and matrix multiplication, but without additional context, it's difficult to provide a precise interpretation of the symbols and their meaning.
2024-05-08 19:50:03 | INFO | stdout | {'text': 'この猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？', 'files': ['/tmp/gradio/b7b8f04e74cda37d9a574c1a2098d7e4ee97b212/user_example_05.jpg']}
2024-05-08 19:50:03 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 37
2024-05-08 19:50:03 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 19:50:03 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:50:03 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:50:03 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nこの猫の目の大きさは、どのような理由で他の猫と比べて特に大きく見えますか？<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['6a216b113245e21e8b9f3b2f14599730']"}
2024-05-08 19:50:11 | INFO | gradio_web_server | この猫の目の大きさが他の猫と比べて特に大きく見える理由は、写真の角度と焦点の位置によるものです。写真は猫の正面から撮影されており、猫の目がカメラに直面しているため、目がより目立つように写っています。また、猫の顔が写真の中心に位置しており、他の部分が遠くに写っているため、猫の目がより目立つように写っています。この効果は、写真の構成と焦点の位置によって引き起こされる視覚的な効果です。
2024-05-08 19:50:15 | INFO | stdout | {'text': 'What characters are used in this captcha? Write them sequentially', 'files': ['/tmp/gradio/675b15299f526cc866e41cae0f1fbaf3565e4b90/user_example_03.jpg']}
2024-05-08 19:50:15 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 65
2024-05-08 19:50:15 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 19:50:15 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:50:15 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:50:16 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat characters are used in this captcha? Write them sequentially<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['67fc0a3522d64360fa776288d8005526']"}
2024-05-08 19:50:18 | INFO | gradio_web_server | The characters used in this captcha are: 6, t, q, b, c, d, s.
2024-05-08 19:50:44 | INFO | stdout | {'text': "What's the difference with them?", 'files': ['/tmp/gradio/447d9ea0a12a7be4cf7f279dc4e667b1b938a0c2/FreQhvkWYAE91JQ.jpg', '/tmp/gradio/bd584df86fb00f971ddff082855b76179486b77a/brianbo_an_otter_is_standing_in_front_of_a_obelisk_in_fairy_tal_185a3c30-049e-47e3-95ac-c7c535a763f8.png']}
2024-05-08 19:50:44 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 32
2024-05-08 19:50:44 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:50:44 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:50:44 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:50:44 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat's the difference with them?<|im_end|>\n<|im_start|>assistant\n", 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 2 images: ['65751e395490de6e42d3232c62d38b49', '5ebe6fad6247a492c93f66cabd77e504']"}
2024-05-08 19:50:58 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-05-08 19:50:59 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:50:59 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2553, in block_thread
2024-05-08 19:50:59 | ERROR | stderr |     time.sleep(0.1)
2024-05-08 19:50:59 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:50:59 | ERROR | stderr | 
2024-05-08 19:50:59 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-05-08 19:50:59 | ERROR | stderr | 
2024-05-08 19:50:59 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:50:59 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 606, in <module>
2024-05-08 19:50:59 | ERROR | stderr |     demo.queue(api_open=False).launch(
2024-05-08 19:50:59 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2458, in launch
2024-05-08 19:50:59 | ERROR | stderr |     self.block_thread()
2024-05-08 19:50:59 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2557, in block_thread
2024-05-08 19:50:59 | ERROR | stderr |     self.server.close()
2024-05-08 19:50:59 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/http_server.py", line 68, in close
2024-05-08 19:50:59 | ERROR | stderr |     self.thread.join(timeout=5)
2024-05-08 19:50:59 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1100, in join
2024-05-08 19:50:59 | ERROR | stderr |     self._wait_for_tstate_lock(timeout=max(timeout, 0))
2024-05-08 19:50:59 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
2024-05-08 19:50:59 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-05-08 19:50:59 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:51:22 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:51:22 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:51:23 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:51:23 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:51:23 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:51:23 | INFO | stdout | 
2024-05-08 19:51:23 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:51:31 | INFO | stdout | {'text': 'What is the latex code for this image?', 'files': ['/tmp/gradio/a3cc6651cc472468fe9481a1d92fa5de88e2b76e/user_example_04.jpg']}
2024-05-08 19:51:31 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 38
2024-05-08 19:51:31 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 19:51:31 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:51:31 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:51:31 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat is the latex code for this image?<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['450ac58e36d9dd61d78c8b1247a5dffe']"}
2024-05-08 19:51:51 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:52:06 | INFO | stdout | {'text': "What's the difference between them?", 'files': ['/tmp/gradio/447d9ea0a12a7be4cf7f279dc4e667b1b938a0c2/FreQhvkWYAE91JQ.jpg', '/tmp/gradio/bd584df86fb00f971ddff082855b76179486b77a/brianbo_an_otter_is_standing_in_front_of_a_obelisk_in_fairy_tal_185a3c30-049e-47e3-95ac-c7c535a763f8.png']}
2024-05-08 19:52:06 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 35
2024-05-08 19:52:07 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:52:07 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:52:07 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:52:07 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat's the difference between them?<|im_end|>\n<|im_start|>assistant\n", 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 2 images: ['65751e395490de6e42d3232c62d38b49', '5ebe6fad6247a492c93f66cabd77e504']"}
2024-05-08 19:52:13 | INFO | stdout | {'text': 'What is the latex code for this image?', 'files': ['/tmp/gradio/a3cc6651cc472468fe9481a1d92fa5de88e2b76e/user_example_04.jpg']}
2024-05-08 19:52:13 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 38
2024-05-08 19:52:13 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 19:52:13 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:52:13 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:52:13 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat is the latex code for this image?<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['450ac58e36d9dd61d78c8b1247a5dffe']"}
2024-05-08 19:52:53 | INFO | gradio_web_server | The LaTeX code for the mathematical expressions in the image is as follows:

```latex
\begin{align*}
\Omega_{\ell} &= \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} \\
&= \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} \\
&= \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \sum_{i=1}^{d} W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} + \cdots + W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)} \\
&= W_{\ell, i} \cdot \mathbf{1}^{\top} \cdot \mathbf{W}_{\ell}^{(i)}
\end{align*}
```

Please note that the LaTeX code provided is a transcription of the mathematical expressions shown in the image, and it may not be a complete or accurate representation of the intended mathematical content. The expressions involve summations and matrix multiplication, but without additional context, it's difficult to provide a precise interpretation of the symbols and their meaning.
2024-05-08 19:54:16 | INFO | stdout | {'text': "What's the difference between them?", 'files': ['/tmp/gradio/447d9ea0a12a7be4cf7f279dc4e667b1b938a0c2/FreQhvkWYAE91JQ.jpg', '/tmp/gradio/bd584df86fb00f971ddff082855b76179486b77a/brianbo_an_otter_is_standing_in_front_of_a_obelisk_in_fairy_tal_185a3c30-049e-47e3-95ac-c7c535a763f8.png']}
2024-05-08 19:54:18 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 35
2024-05-08 19:55:49 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:55:49 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:55:49 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:55:49 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nWhat's the difference between them?<|im_end|>\n<|im_start|>assistant\n", 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 2 images: ['65751e395490de6e42d3232c62d38b49', '5ebe6fad6247a492c93f66cabd77e504']"}
2024-05-08 19:56:27 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:56:27 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:56:27 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:56:27 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='once', share=False, moderate=False, embed=False)
2024-05-08 19:56:27 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:56:28 | INFO | stdout | 
2024-05-08 19:56:28 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 19:56:34 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198. params: {}
2024-05-08 19:56:40 | INFO | stdout | {'text': '请针对于这幅画写一首中文古诗。', 'files': ['/tmp/gradio/0266b3f7b9311a93f0f38bc8cf0698b019c829b1/user_example_09.jpg']}
2024-05-08 19:56:40 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 15
2024-05-08 19:56:43 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:56:43 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:56:43 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:56:43 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\n请针对于这幅画写一首中文古诗。<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['14dc2eeafa58f977589b57749e8b0eeb']"}
2024-05-08 19:56:50 | INFO | gradio_web_server | 星河灿烂，月光洒落，
山丘静谧，村庄安详。
梵高笔下，色彩斑斓，
描绘星空，尽展辉煌。

夜幕降临，月升天际，
繁星点点，如梦似幻。
梵高之笔，挥洒自如，
尽展宇宙，无尽奥秘。

山丘起伏，村庄静谧，
梵高之心，尽展眼前。
星空灿烂，月光洒落，
尽展梵高，艺术魅力。
2024-05-08 19:57:05 | INFO | stdout | {'text': "What's the difference between them?", 'files': ['/tmp/gradio/447d9ea0a12a7be4cf7f279dc4e667b1b938a0c2/FreQhvkWYAE91JQ.jpg', '/tmp/gradio/bd584df86fb00f971ddff082855b76179486b77a/brianbo_an_otter_is_standing_in_front_of_a_obelisk_in_fairy_tal_185a3c30-049e-47e3-95ac-c7c535a763f8.png']}
2024-05-08 19:57:05 | INFO | gradio_web_server | add_text. ip: 124.246.66.198. len: 35
2024-05-08 19:57:05 | INFO | gradio_web_server | http_bot. ip: 124.246.66.198
2024-05-08 19:57:05 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 19:57:05 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 19:57:05 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image><image>\nWhat's the difference between them?<|im_end|>\n<|im_start|>assistant\n", 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 2 images: ['65751e395490de6e42d3232c62d38b49', '5ebe6fad6247a492c93f66cabd77e504']"}
2024-05-08 19:59:13 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-05-08 19:59:14 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2553, in block_thread
2024-05-08 19:59:14 | ERROR | stderr |     time.sleep(0.1)
2024-05-08 19:59:14 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:59:14 | ERROR | stderr | 
2024-05-08 19:59:14 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-05-08 19:59:14 | ERROR | stderr | 
2024-05-08 19:59:14 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/runpy.py", line 196, in _run_module_as_main
2024-05-08 19:59:14 | ERROR | stderr |     return _run_code(code, main_globals, None,
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/runpy.py", line 86, in _run_code
2024-05-08 19:59:14 | ERROR | stderr |     exec(code, run_globals)
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py", line 39, in <module>
2024-05-08 19:59:14 | ERROR | stderr |     cli.main()
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 430, in main
2024-05-08 19:59:14 | ERROR | stderr |     run()
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 284, in run_file
2024-05-08 19:59:14 | ERROR | stderr |     runpy.run_path(target, run_name="__main__")
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 321, in run_path
2024-05-08 19:59:14 | ERROR | stderr |     return _run_module_code(code, init_globals, run_name,
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 135, in _run_module_code
2024-05-08 19:59:14 | ERROR | stderr |     _run_code(code, mod_globals, init_globals,
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/.cursor-server/extensions/ms-python.python-2023.22.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 124, in _run_code
2024-05-08 19:59:14 | ERROR | stderr |     exec(code, run_globals)
2024-05-08 19:59:14 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 606, in <module>
2024-05-08 19:59:14 | ERROR | stderr |     demo.queue(api_open=False).launch(
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2458, in launch
2024-05-08 19:59:14 | ERROR | stderr |     self.block_thread()
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2557, in block_thread
2024-05-08 19:59:14 | ERROR | stderr |     self.server.close()
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/http_server.py", line 68, in close
2024-05-08 19:59:14 | ERROR | stderr |     self.thread.join(timeout=5)
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1100, in join
2024-05-08 19:59:14 | ERROR | stderr |     self._wait_for_tstate_lock(timeout=max(timeout, 0))
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
2024-05-08 19:59:14 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-05-08 19:59:14 | ERROR | stderr | KeyboardInterrupt
2024-05-08 19:59:14 | ERROR | stderr | Exception ignored in: <module 'threading' from '/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py'>
2024-05-08 19:59:14 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 19:59:14 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1567, in _shutdown
2024-05-08 19:59:14 | ERROR | stderr |     lock.acquire()
2024-05-08 19:59:14 | ERROR | stderr | KeyboardInterrupt:
2024-05-08 19:59:30 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 19:59:30 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='reload', share=False, moderate=False, embed=False)
2024-05-08 19:59:31 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 19:59:31 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50010', concurrency_count=16, model_list_mode='reload', share=False, moderate=False, embed=False)
2024-05-08 19:59:31 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 19:59:31 | INFO | stdout | 
2024-05-08 19:59:31 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 20:05:21 | INFO | gradio_web_server | load_demo. ip: 124.246.66.198
2024-05-08 20:05:21 | INFO | gradio_web_server | Models: []
2024-05-08 20:05:21 | ERROR | stderr | /home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/components/dropdown.py:179: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include:  or set allow_custom_value=True.
2024-05-08 20:05:21 | ERROR | stderr |   warnings.warn(
2024-05-08 20:06:27 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-05-08 20:06:28 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 20:06:28 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2553, in block_thread
2024-05-08 20:06:28 | ERROR | stderr |     time.sleep(0.1)
2024-05-08 20:06:28 | ERROR | stderr | KeyboardInterrupt
2024-05-08 20:06:28 | ERROR | stderr | 
2024-05-08 20:06:28 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-05-08 20:06:28 | ERROR | stderr | 
2024-05-08 20:06:28 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 20:06:28 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 606, in <module>
2024-05-08 20:06:28 | ERROR | stderr |     demo.queue(api_open=False).launch(
2024-05-08 20:06:28 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2458, in launch
2024-05-08 20:06:28 | ERROR | stderr |     self.block_thread()
2024-05-08 20:06:28 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 2557, in block_thread
2024-05-08 20:06:28 | ERROR | stderr |     self.server.close()
2024-05-08 20:06:28 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/http_server.py", line 68, in close
2024-05-08 20:06:28 | ERROR | stderr |     self.thread.join(timeout=5)
2024-05-08 20:06:28 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1100, in join
2024-05-08 20:06:28 | ERROR | stderr |     self._wait_for_tstate_lock(timeout=max(timeout, 0))
2024-05-08 20:06:28 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
2024-05-08 20:06:28 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-05-08 20:06:28 | ERROR | stderr | KeyboardInterrupt
2024-05-08 20:10:54 | INFO | stdout | /mnt/bn/vl-research/workspace/boli01/projects/demos
2024-05-08 20:10:54 | INFO | gradio_web_server | args: Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50020', concurrency_count=16, model_list_mode='reload', share=False, moderate=False, embed=False)
2024-05-08 20:10:54 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 20:10:54 | INFO | gradio_web_server | Namespace(host='0.0.0.0', port=None, controller_url='http://localhost:50020', concurrency_count=16, model_list_mode='reload', share=False, moderate=False, embed=False)
2024-05-08 20:10:55 | INFO | stdout | Running on local URL:  http://0.0.0.0:7860
2024-05-08 20:10:55 | INFO | stdout | 
2024-05-08 20:10:55 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-05-08 20:12:39 | INFO | gradio_web_server | load_demo. ip: 24.240.45.225
2024-05-08 20:12:39 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 20:12:52 | INFO | stdout | {'text': '这个是什么猫？它在干啥？', 'files': ['/tmp/gradio/3c94cf4ccdbb877666285b42dd9263073d1fa19c/user_example_07.jpg']}
2024-05-08 20:12:52 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 12
2024-05-08 20:12:52 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/PIL/JpegImagePlugin.py", line 650, in _save
2024-05-08 20:12:52 | ERROR | stderr |     rawmode = RAWMODE[im.mode]
2024-05-08 20:12:52 | ERROR | stderr | KeyError: 'RGBA'
2024-05-08 20:12:52 | ERROR | stderr | 
2024-05-08 20:12:52 | ERROR | stderr | The above exception was the direct cause of the following exception:
2024-05-08 20:12:52 | ERROR | stderr | 
2024-05-08 20:12:52 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/routes.py", line 733, in predict
2024-05-08 20:12:52 | ERROR | stderr |     output = await route_utils.call_process_api(
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 20:12:52 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1847, in process_api
2024-05-08 20:12:52 | ERROR | stderr |     result = await self.call_function(
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1433, in call_function
2024-05-08 20:12:52 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-05-08 20:12:52 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2144, in run_sync_in_worker_thread
2024-05-08 20:12:52 | ERROR | stderr |     return await future
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-05-08 20:12:52 | ERROR | stderr |     result = context.run(func, *args)
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 805, in wrapper
2024-05-08 20:12:52 | ERROR | stderr |     response = f(*args, **kwargs)
2024-05-08 20:12:52 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 160, in add_text
2024-05-08 20:12:52 | ERROR | stderr |     return (state, state.to_gradio_chatbot(), gr.MultimodalTextbox(value=None, interactive=True), None) + (disable_btn,) * 5
2024-05-08 20:12:52 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/LLaVA_Next/llava/conversation.py", line 250, in to_gradio_chatbot
2024-05-08 20:12:52 | ERROR | stderr |     img_b64_str = self.process_image(img, "Default", return_pil=False, image_format="JPEG")
2024-05-08 20:12:52 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/LLaVA_Next/llava/conversation.py", line 220, in process_image
2024-05-08 20:12:52 | ERROR | stderr |     image.save(buffered, format=image_format)
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/PIL/Image.py", line 2459, in save
2024-05-08 20:12:52 | ERROR | stderr |     save_handler(self, fp, filename)
2024-05-08 20:12:52 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/PIL/JpegImagePlugin.py", line 653, in _save
2024-05-08 20:12:52 | ERROR | stderr |     raise OSError(msg) from e
2024-05-08 20:12:52 | ERROR | stderr | OSError: cannot write mode RGBA as JPEG
2024-05-08 20:12:52 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 20:12:52 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 20:12:52 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.###Human: What are the key differences between renewable and non-renewable energy sources?###Assistant: Renewable energy sources are those that can be replenished naturally in a relatively short amount of time, such as solar, wind, hydro, geothermal, and biomass. Non-renewable energy sources, on the other hand, are finite and will eventually be depleted, such as coal, oil, and natural gas. Here are some key differences between renewable and non-renewable energy sources:\n1. Availability: Renewable energy sources are virtually inexhaustible, while non-renewable energy sources are finite and will eventually run out.\n2. Environmental impact: Renewable energy sources have a much lower environmental impact than non-renewable sources, which can lead to air and water pollution, greenhouse gas emissions, and other negative effects.\n3. Cost: Renewable energy sources can be more expensive to initially set up, but they typically have lower operational costs than non-renewable sources.\n4. Reliability: Renewable energy sources are often more reliable and can be used in more remote locations than non-renewable sources.\n5. Flexibility: Renewable energy sources are often more flexible and can be adapted to different situations and needs, while non-renewable sources are more rigid and inflexible.\n6. Sustainability: Renewable energy sources are more sustainable over the long term, while non-renewable sources are not, and their depletion can lead to economic and social instability.\n###", 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': '###', 'images': 'List of 0 images: []'}
2024-05-08 20:12:52 | INFO | gradio_web_server | Human:
2024-05-08 20:12:54 | INFO | stdout | {'text': '这个是什么猫？它在干啥？', 'files': ['/tmp/gradio/3c94cf4ccdbb877666285b42dd9263073d1fa19c/user_example_07.jpg']}
2024-05-08 20:12:54 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 12
2024-05-08 20:12:55 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/PIL/JpegImagePlugin.py", line 650, in _save
2024-05-08 20:12:55 | ERROR | stderr |     rawmode = RAWMODE[im.mode]
2024-05-08 20:12:55 | ERROR | stderr | KeyError: 'RGBA'
2024-05-08 20:12:55 | ERROR | stderr | 
2024-05-08 20:12:55 | ERROR | stderr | The above exception was the direct cause of the following exception:
2024-05-08 20:12:55 | ERROR | stderr | 
2024-05-08 20:12:55 | ERROR | stderr | Traceback (most recent call last):
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/routes.py", line 733, in predict
2024-05-08 20:12:55 | ERROR | stderr |     output = await route_utils.call_process_api(
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/route_utils.py", line 270, in call_process_api
2024-05-08 20:12:55 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1847, in process_api
2024-05-08 20:12:55 | ERROR | stderr |     result = await self.call_function(
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/blocks.py", line 1433, in call_function
2024-05-08 20:12:55 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-05-08 20:12:55 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 2144, in run_sync_in_worker_thread
2024-05-08 20:12:55 | ERROR | stderr |     return await future
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-05-08 20:12:55 | ERROR | stderr |     result = context.run(func, *args)
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/gradio/utils.py", line 805, in wrapper
2024-05-08 20:12:55 | ERROR | stderr |     response = f(*args, **kwargs)
2024-05-08 20:12:55 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/demos/serve/gradio_web_server.py", line 160, in add_text
2024-05-08 20:12:55 | ERROR | stderr |     return (state, state.to_gradio_chatbot(), gr.MultimodalTextbox(value=None, interactive=True), None) + (disable_btn,) * 5
2024-05-08 20:12:55 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/LLaVA_Next/llava/conversation.py", line 250, in to_gradio_chatbot
2024-05-08 20:12:55 | ERROR | stderr |     img_b64_str = self.process_image(img, "Default", return_pil=False, image_format="JPEG")
2024-05-08 20:12:55 | ERROR | stderr |   File "/mnt/bn/vl-research/workspace/boli01/projects/LLaVA_Next/llava/conversation.py", line 220, in process_image
2024-05-08 20:12:55 | ERROR | stderr |     image.save(buffered, format=image_format)
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/PIL/Image.py", line 2459, in save
2024-05-08 20:12:55 | ERROR | stderr |     save_handler(self, fp, filename)
2024-05-08 20:12:55 | ERROR | stderr |   File "/home/tiger/miniconda3/envs/sglang/lib/python3.10/site-packages/PIL/JpegImagePlugin.py", line 653, in _save
2024-05-08 20:12:55 | ERROR | stderr |     raise OSError(msg) from e
2024-05-08 20:12:55 | ERROR | stderr | OSError: cannot write mode RGBA as JPEG
2024-05-08 20:12:55 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 20:12:55 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 20:12:55 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.###Human: What are the key differences between renewable and non-renewable energy sources?###Assistant: Human:###", 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': '###', 'images': 'List of 0 images: []'}
2024-05-08 20:12:55 | INFO | gradio_web_server | None
2024-05-08 20:12:56 | INFO | gradio_web_server | load_demo. ip: 24.240.45.225
2024-05-08 20:12:56 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 20:12:58 | INFO | stdout | {'text': '请针对于这幅画写一首中文古诗。', 'files': ['/tmp/gradio/0266b3f7b9311a93f0f38bc8cf0698b019c829b1/user_example_09.jpg']}
2024-05-08 20:12:58 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 15
2024-05-08 20:12:58 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 20:12:58 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 20:12:58 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 20:12:58 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\n请针对于这幅画写一首中文古诗。<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['14dc2eeafa58f977589b57749e8b0eeb']"}
2024-05-08 20:13:06 | INFO | gradio_web_server | load_demo. ip: 24.240.45.225
2024-05-08 20:13:06 | INFO | gradio_web_server | Models: ['llava-next-72b']
2024-05-08 20:13:09 | INFO | stdout | {'text': 'Explain this diagram.', 'files': ['/tmp/gradio/7f718391e606e46b9d40e4948a1e8cb262335699/user_example_01.jpg']}
2024-05-08 20:13:09 | INFO | gradio_web_server | add_text. ip: 24.240.45.225. len: 21
2024-05-08 20:13:09 | INFO | gradio_web_server | http_bot. ip: 24.240.45.225
2024-05-08 20:13:09 | INFO | gradio_web_server | ============= template_name: qwen_1_5 =============
2024-05-08 20:13:09 | INFO | gradio_web_server | model_name: llava-next-72b, worker_addr: http://localhost:40000
2024-05-08 20:13:09 | INFO | gradio_web_server | ==== request ====
{'model': 'llava-next-72b', 'prompt': '<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\nExplain this diagram.<|im_end|>\n<|im_start|>assistant\n', 'temperature': 0.0, 'top_p': 0.7, 'max_new_tokens': 1024, 'stop': None, 'images': "List of 1 images: ['91d6a4b55dd3ab9c0293c0dbd1ed2d4a']"}
2024-05-08 20:14:06 | INFO | gradio_web_server | The diagram you've provided appears to be a simplified representation of a computer system architecture, focusing on the hardware components and their connections. Here's a breakdown of the components and their functions as depicted in the diagram:

1. **CPU (Central Processing Unit)**: This is the brain of the computer, responsible for executing instructions and controlling the operation of the computer system.

2. **ROM (Read-Only Memory)**: This is a type of non-volatile memory that retains its data even when the power is turned off.

3. **RAM (Random Access Memory)**: This is a type of volatile memory that temporarily stores data that the CPU needs to access quickly.

4. **HDD (Hard Disk Drive)**: This is a non-volatile storage device that stores and retrieves digital information using one or more rigid rapidly rotating disks coated with magnetic material.

5. **Display**: This is the output device that allows the user to see the visual representation of the computer's output.

6. **Network (I/F)**: This stands for "Interface" and represents the hardware and software that allow the computer to communicate with other devices on a network.

7. **Keyboard**: This is an input device used to enter text or commands into the computer.

8. **Mouse**: This is an input device that allows the user to interact with the computer by pointing and clicking.

9. **Media (I/F)**: This likely refers to an interface for handling media, such as CDs or DVDs.

10. **CD-RW Drive**: This is a device that can read, write, and rewrite data on CD-RW discs.

11. **Recording Medium**: This could refer to any storage device used for recording data, such as a hard drive, CD, or DVD.

12. **304 (504)**: This could be a specific model or part number for a component, possibly a type of memory or storage device.

13. **305 (505)**: Similar to the above, this could be another model or part number for a component.

14. **308 (508)**: Again, this could be a model or part number for a component.

15. **310 (510)**: This could be a model or part number for a component, possibly a network interface card or a specific type of storage device.

16. **311 (511)**: This could be a model or part number for a component, possibly a keyboard or a mouse.

17. **312 (512)**: This could be a model or part number for a component, possibly a sound card or a specific type of storage device.

18. **313 (513)**: This could be a model or part number for a component, possibly a CD-RW drive or a specific type of storage device.

19. **314 (514)**: This could be a model or part number for a component, possibly a specific type of recording medium.

20. **309 (509)**: This could be a model or part number for a component, possibly a network interface card or a specific type of storage device.

21. **307 (507)**: This could be a model or part number for a component, possibly a specific type of storage device.

22. **306 (506)**: This could be a model or part number for a component, possibly a specific type of storage device.

The numbers in parentheses (e.g., 504, 505, etc.) might indicate a specific version or revision of the component, or they could be part numbers for the components used in the system.

The arrows indicate the flow of data or the connections between these components. For example, the CPU is connected to the RAM, ROM, and HDD, which suggests that the CPU can access data from these storage devices. The keyboard and mouse are connected to the CPU, indicating that they are input devices that send data to the CPU. The display is connected to the CPU, which means that the CPU sends data to the display for output.

The diagram is a bit abstract and lacks specific details about the connections and the nature of the components, but it gives a general idea of how the different parts of a computer system are connected and interact with each other.
